<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[K8s调度器及调度队列源码分析]]></title>
    <url>%2F2021%2F06%2F08%2FK8s%E8%B0%83%E5%BA%A6%E5%99%A8%E5%8F%8A%E8%B0%83%E5%BA%A6%E9%98%9F%E5%88%97%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介在 Kubernetes 中，调度是指将 Pod 放置到合适的 Node 上，然后对应 Node 上的 kubelet 才能够运行这些 Pod。K8s scheduler 就是用来调度 pod 的一个组件。 本文主要是通过源码了解调度器的部分工作流程。 源码分析 Based on Kubernetes v1.19.11. K8s scheduler 主要的数据结构是： Scheduler。 SchedulingQueue。 相关的代码流程主要分为两个部分： cmd/kube-scheduler，这里是我们调度器的起始处，主要是读取配置，初始化并启动调度器。 pkg/scheduler，这里是调度器的核心代码。 数据结构Scheduler1234567891011121314151617181920212223242526272829303132// pkg/scheduler/scheduler.go// Scheduler watches for new unscheduled pods. It attempts to find// nodes that they fit on and writes bindings back to the api server.type Scheduler struct &#123; // It is expected that changes made via SchedulerCache will be observed // by NodeLister and Algorithm. SchedulerCache internalcache.Cache Algorithm core.ScheduleAlgorithm // NextPod should be a function that blocks until the next pod // is available. We don't use a channel for this, because scheduling // a pod may take some amount of time and we don't want pods to get // stale while they sit in a channel. NextPod func() *framework.QueuedPodInfo // Error is called if there is an error. It is passed the pod in // question, and the error Error func(*framework.QueuedPodInfo, error) // Close this to shut down the scheduler. StopEverything &lt;-chan struct&#123;&#125; // SchedulingQueue holds pods to be scheduled SchedulingQueue internalqueue.SchedulingQueue // Profiles are the scheduling profiles. Profiles profile.Map scheduledPodsHasSynced func() bool client clientset.Interface&#125; SchedulerCache ，保存了调度所需的 podStates 和 nodeInfos。 Algorithm ，会使用该对象的 Schedule 方法来运行调度逻辑。 SchedulingQueue ，调度队列。 Profiles ，调度器配置。 SchedulingQueue Interface 123456789101112131415161718192021222324252627282930313233// pkg/scheduler/internal/queue/scheduling_queue.go// SchedulingQueue is an interface for a queue to store pods waiting to be scheduled.// The interface follows a pattern similar to cache.FIFO and cache.Heap and// makes it easy to use those data structures as a SchedulingQueue.type SchedulingQueue interface &#123; framework.PodNominator Add(pod *v1.Pod) error // AddUnschedulableIfNotPresent adds an unschedulable pod back to scheduling queue. // The podSchedulingCycle represents the current scheduling cycle number which can be // returned by calling SchedulingCycle(). AddUnschedulableIfNotPresent(pod *framework.QueuedPodInfo, podSchedulingCycle int64) error // SchedulingCycle returns the current number of scheduling cycle which is // cached by scheduling queue. Normally, incrementing this number whenever // a pod is popped (e.g. called Pop()) is enough. SchedulingCycle() int64 // Pop removes the head of the queue and returns it. It blocks if the // queue is empty and waits until a new item is added to the queue. Pop() (*framework.QueuedPodInfo, error) Update(oldPod, newPod *v1.Pod) error Delete(pod *v1.Pod) error MoveAllToActiveOrBackoffQueue(event string) AssignedPodAdded(pod *v1.Pod) AssignedPodUpdated(pod *v1.Pod) PendingPods() []*v1.Pod // Close closes the SchedulingQueue so that the goroutine which is // waiting to pop items can exit gracefully. Close() // NumUnschedulablePods returns the number of unschedulable pods exist in the SchedulingQueue. NumUnschedulablePods() int // Run starts the goroutines managing the queue. Run()&#125; Implementation 12345678910111213141516171819202122232425262728293031323334353637383940414243// PriorityQueue implements a scheduling queue.// The head of PriorityQueue is the highest priority pending pod. This structure// has three sub queues. One sub-queue holds pods that are being considered for// scheduling. This is called activeQ and is a Heap. Another queue holds// pods that are already tried and are determined to be unschedulable. The latter// is called unschedulableQ. The third queue holds pods that are moved from// unschedulable queues and will be moved to active queue when backoff are completed.type PriorityQueue struct &#123; // PodNominator abstracts the operations to maintain nominated Pods. framework.PodNominator stop chan struct&#123;&#125; clock util.Clock // pod initial backoff duration. podInitialBackoffDuration time.Duration // pod maximum backoff duration. podMaxBackoffDuration time.Duration lock sync.RWMutex cond sync.Cond // activeQ is heap structure that scheduler actively looks at to find pods to // schedule. Head of heap is the highest priority pod. activeQ *heap.Heap // podBackoffQ is a heap ordered by backoff expiry. Pods which have completed backoff // are popped from this heap before the scheduler looks at activeQ podBackoffQ *heap.Heap // unschedulableQ holds pods that have been tried and determined unschedulable. unschedulableQ *UnschedulablePodsMap // schedulingCycle represents sequence number of scheduling cycle and is incremented // when a pod is popped. schedulingCycle int64 // moveRequestCycle caches the sequence number of scheduling cycle when we // received a move request. Unscheduable pods in and before this scheduling // cycle will be put back to activeQueue if we were trying to schedule them // when we received move request. moveRequestCycle int64 // closed indicates that the queue is closed. // It is mainly used to let Pop() exit its control loop while waiting for an item. closed bool&#125; PodNominator：调度算法调度的结果，保存了 Pod 和 Node 的关系。 cond：用来控制调度队列的 Pop 操作。 activeQ：用堆维护的优先队列，保存着待调度的 pod，其中优先级默认是根据 Pod 的优先级和创建时间来排序。 podBackoffQ：同样是用堆维护的优先队列，保存着运行失败的 Pod，优先级是根据 backOffTime 来排序，backOffTime 受 podInitialBackoffDuration 以及 podMaxBackoffDuration 两个参数影响。 unschedulableQ：是一个 Map 结构，保存着暂时无法调度（可能是资源不满足等情况）的 Pod。 cmd/kube-scheduler调度器的入口 main最开始，scheduler 在 cmd/kube-scheduler/scheduler.go 使用 NewSchedulerCommand() 初始化命令并执行命令。 12345678910// cmd/kube-scheduler/scheduler.gofunc main() &#123; ... command := app.NewSchedulerCommand() ... if err := command.Execute(); err != nil &#123; os.Exit(1) &#125;&#125; 初始化调度器命令 NewSchedulerCommandNewSchedulerCommand() 会读取配置文件和参数，初始化调度命令，其中最主要的函数是 runCommand()。 1234567891011121314151617func NewSchedulerCommand(registryOptions ...Option) *cobra.Command &#123; ... cmd := &amp;cobra.Command&#123; Use: "kube-scheduler", ... Run: func(cmd *cobra.Command, args []string) &#123; if err := runCommand(cmd, opts, registryOptions...); err != nil &#123; fmt.Fprintf(os.Stderr, "%v\n", err) os.Exit(1) &#125; &#125;, ... &#125; ... return cmd&#125; 执行调度器命令 runCommandrunCommand 主要分为两个重要步骤： Setup ：读取配置文件以及参数，初始化调度器。这里的配置文件包括 Profiles 配置等。 Run：运行调度器所需的组件，例如健康检查服务，Informer 等。然后使用 Setup 得到的调度器运行调度的主流程。 12345678910func runCommand(cmd *cobra.Command, opts *options.Options, registryOptions ...Option) error &#123; ... cc, sched, err := Setup(ctx, opts, registryOptions...) if err != nil &#123; return err &#125; return Run(ctx, cc, sched)&#125; 创建调度器 SetupSetup 会根据配置文件和参数创建 scheduler。这里个人觉得最主要的是 Profiles，里面定义了调度器的名字，以及 scheduling framework 的插件配置。还有一些可以用来调优的参数，例如 PercentageOfNodesToScore, PodInitialBackoffSeconds , PodMaxBackoffSeconds 等。 并且 scheduler.New() 中会有一个 addAllEventHandlers(sched, informerFactory, podInformer) 函数，启动所有资源对象的事件监听，来根据情况调用对应的回调函数，这些回调函数同时也会影响调度队列的运行过程。 12345678910111213141516171819202122func Setup(ctx context.Context, opts *options.Options, outOfTreeRegistryOptions ...Option) (*schedulerserverconfig.CompletedConfig, *scheduler.Scheduler, error) &#123; ... // Create the scheduler. sched, err := scheduler.New(cc.Client, cc.InformerFactory, cc.PodInformer, recorderFactory, ctx.Done(), scheduler.WithProfiles(cc.ComponentConfig.Profiles...), scheduler.WithAlgorithmSource(cc.ComponentConfig.AlgorithmSource), scheduler.WithPercentageOfNodesToScore(cc.ComponentConfig.PercentageOfNodesToScore), scheduler.WithFrameworkOutOfTreeRegistry(outOfTreeRegistry), scheduler.WithPodMaxBackoffSeconds(cc.ComponentConfig.PodMaxBackoffSeconds), scheduler.WithPodInitialBackoffSeconds(cc.ComponentConfig.PodInitialBackoffSeconds), scheduler.WithExtenders(cc.ComponentConfig.Extenders...), ) if err != nil &#123; return nil, nil, err &#125; return &amp;cc, sched, nil&#125; 运行调度器 RunRun 主要是启动一些组件，然后调用 sched.Run(ctx) 进行调度的主流程。 123456789101112131415161718192021func Run(ctx context.Context, cc *schedulerserverconfig.CompletedConfig, sched *scheduler.Scheduler) error &#123; ... // Prepare the event broadcaster. cc.EventBroadcaster.StartRecordingToSink(ctx.Done()) // Setup healthz checks. ... // Start up the healthz server. ... // Start all informers. go cc.PodInformer.Informer().Run(ctx.Done()) cc.InformerFactory.Start(ctx.Done()) // Wait for all caches to sync before scheduling. cc.InformerFactory.WaitForCacheSync(ctx.Done()) // If leader election is enabled, runCommand via LeaderElector until done and exit. // Leader election ... // Leader election is disabled, so runCommand inline until done. sched.Run(ctx) return fmt.Errorf("finished without leader elect")&#125; pkg/scheduler运行调度器主流程Run 会启动 scheduling queue，并不断调用 sched.scheduleOne() 进行调度。 123456789// Run begins watching and scheduling. It waits for cache to be synced, then starts scheduling and blocked until the context is done.func (sched *Scheduler) Run(ctx context.Context) &#123; if !cache.WaitForCacheSync(ctx.Done(), sched.scheduledPodsHasSynced) &#123; return &#125; sched.SchedulingQueue.Run() wait.UntilWithContext(ctx, sched.scheduleOne, 0) sched.SchedulingQueue.Close()&#125; 运行调度队列12345// Run starts the goroutine to pump from podBackoffQ to activeQfunc (p *PriorityQueue) Run() &#123; go wait.Until(p.flushBackoffQCompleted, 1.0*time.Second, p.stop) go wait.Until(p.flushUnschedulableQLeftover, 30*time.Second, p.stop)&#125; 调度队列的运行逻辑： 每隔 1s 检查 podBackoffQ 是否有 pod 可以放入 activeQ 中。检查的逻辑是判断 backOffTime 是否已经到期。 每隔 30s 检查 unschedulableQ 是否有 pod 可以放入 activeQ 中。 单个 Pod 的调度 scheduleOne在介绍 scheduleOne 之前，看这张 pod 调度流程图能有助于我们理清整个过程。同时这也是 k8s v1.15 开始支持的 Scheduling Framework 的 Plugin 扩展点。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// scheduleOne does the entire scheduling workflow for a single pod. It is serialized on the scheduling algorithm's host fitting.func (sched *Scheduler) scheduleOne(ctx context.Context) &#123; podInfo := sched.NextPod() ... pod := podInfo.Pod prof, err := sched.profileForPod(pod) ... // Synchronously attempt to find a fit for the pod. start := time.Now() state := framework.NewCycleState() ... scheduleResult, err := sched.Algorithm.Schedule(schedulingCycleCtx, prof, state, pod) ... // Tell the cache to assume that a pod now is running on a given node, even though it hasn't been bound yet. // This allows us to keep scheduling without waiting on binding to occur. assumedPodInfo := podInfo.DeepCopy() assumedPod := assumedPodInfo.Pod // assume modifies `assumedPod` by setting NodeName=scheduleResult.SuggestedHost err = sched.assume(assumedPod, scheduleResult.SuggestedHost) ... // Run the Reserve method of reserve plugins. if sts := prof.RunReservePluginsReserve(schedulingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost); !sts.IsSuccess() &#123; ... &#125; // Run "permit" plugins. runPermitStatus := prof.RunPermitPlugins(schedulingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost) ... // bind the pod to its host asynchronously (we can do this b/c of the assumption step above). go func() &#123; bindingCycleCtx, cancel := context.WithCancel(ctx) waitOnPermitStatus := prof.WaitOnPermit(bindingCycleCtx, assumedPod) if !waitOnPermitStatus.IsSuccess() &#123; ... return &#125; // Run "prebind" plugins. preBindStatus := prof.RunPreBindPlugins(bindingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost) if !preBindStatus.IsSuccess() &#123; ... return &#125; err := sched.bind(bindingCycleCtx, prof, assumedPod, scheduleResult.SuggestedHost, state) if err != nil &#123; ... &#125; else &#123; // Run "postbind" plugins. prof.RunPostBindPlugins(bindingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost) &#125; &#125;()&#125; ScheduleOne 是调度器的主流程，主要包括以下几步： 调用 sched.NextPod() 拿到下一个需要调度的 pod。后面会对这个过程进行更详细的介绍。 调用 sched.profileForPod(pod) ，根据 pod 中的 schedulerName 拿到针对该 pod 调度的 Profiles。这些 Profiles 就包括了调度插件的配置等。 进行上图中的 Scheduling Cycle 部分，这部分是单线程运行的。 调用 sched.Algorithm.Schedule()。此处包括好几个步骤，其中 PreFilter, Filter 被称为 Predicate，是对节点进行过滤，这里面考虑了节点资源，Pod Affinity，以及 Node Volumn 等情况。而 PreScore , Score , Nomalize Score 又被称为 Priorities，是对节点进行优选打分，这里会得到一个适合当前 Pod 分配上去的 Node。 进行 Reserve 操作，将调度结果缓存。当后面的调度流程执行失败，会进行 Unreserve 进行数据回滚。 进行 Permit 操作，这里是用户自定义的插件，可以使 Pod 进行 allow（允许 Pod 通过 Permit 阶段）、reject（Pod 调度失败）和 wait（可设置超时时间）这三种操作。对于 Gang Scheduling （一批 pod 同时创建成功或同时创建失败），可以在 Permit 对 Pod 进行控制。 进行图中的 Binding Cycle 部分，这部分是起了一个 Goroutine 去完成工作的，不会阻塞调度主流程。 最开始会进行 WaitOnPermit 操作，这里会阻塞判断 Pod 是否 Permit，直到 Pod Permit 状态为 allow 或者 reject 再往下继续运行。 进行 PreBind , Bind , PostBind 操作。这里会调用 k8s apiserver 提供的接口 b.handle.ClientSet().CoreV1().Pods(binding.Namespace).Bind(ctx, binding, metav1.CreateOptions{})，将待调度的 Pod 与选中的节点进行绑定，但是可能会绑定失败，此时会做 Unreserve 操作，将节点上面 Pod 的资源解除预留，然后重新放置到失败队列中。 当 Pod 与 Node 绑定成功后，Node 上面的 kubelet 会 watch 到对应的 event，然后会在节点上创建 Pod，包括创建容器 storage、network 等。等所有的资源都准备完成，kubelet 会把 Pod 状态更新为Running。 SchedulingQueue 细节获取下一个运行的 Pod调度的时候，需要获取一个调度的 pod，即 sched.NextPod() ，其中调用了 SchedulingQueue 的 Pop() 方法。 当 activeQ 中没有元素，会通过 p.cond.Wait() 阻塞，直到 podBackoffQ 或者 unschedulableQ 将元素加入 activeQ 并通过 cond.Broadcast() 来唤醒。 123456789101112131415161718192021222324// Pop removes the head of the active queue and returns it. It blocks if the// activeQ is empty and waits until a new item is added to the queue. It// increments scheduling cycle when a pod is popped.func (p *PriorityQueue) Pop() (*framework.QueuedPodInfo, error) &#123; p.lock.Lock() defer p.lock.Unlock() for p.activeQ.Len() == 0 &#123; // When the queue is empty, invocation of Pop() is blocked until new item is enqueued. // When Close() is called, the p.closed is set and the condition is broadcast, // which causes this loop to continue and return from the Pop(). if p.closed &#123; return nil, fmt.Errorf(queueClosed) &#125; p.cond.Wait() &#125; obj, err := p.activeQ.Pop() if err != nil &#123; return nil, err &#125; pInfo := obj.(*framework.QueuedPodInfo) pInfo.Attempts++ p.schedulingCycle++ return pInfo, err&#125; 将 Pod 加入 activeQ当 pod 加入 activeQ 后，还会从 unschedulableQ 以及 podBackoffQ 中删除对应 pod 的信息，并使用 cond.Broadcast() 来唤醒阻塞的 Pop。 123456789101112131415161718192021222324// Add adds a pod to the active queue. It should be called only when a new pod// is added so there is no chance the pod is already in active/unschedulable/backoff queuesfunc (p *PriorityQueue) Add(pod *v1.Pod) error &#123; p.lock.Lock() defer p.lock.Unlock() pInfo := p.newQueuedPodInfo(pod) if err := p.activeQ.Add(pInfo); err != nil &#123; klog.Errorf("Error adding pod %v to the scheduling queue: %v", nsNameForPod(pod), err) return err &#125; if p.unschedulableQ.get(pod) != nil &#123; klog.Errorf("Error: pod %v is already in the unschedulable queue.", nsNameForPod(pod)) p.unschedulableQ.delete(pod) &#125; // Delete pod from backoffQ if it is backing off if err := p.podBackoffQ.Delete(pInfo); err == nil &#123; klog.Errorf("Error: pod %v is already in the podBackoff queue.", nsNameForPod(pod)) &#125; metrics.SchedulerQueueIncomingPods.WithLabelValues("active", PodAdd).Inc() p.PodNominator.AddNominatedPod(pod, "") p.cond.Broadcast() return nil&#125; 当 Pod 调度失败时进入失败队列当 pod 调度失败时，会调用 sched.Error() ，其中调用了 p.AddUnschedulableIfNotPresent() . 决定 pod 调度失败时进入 podBackoffQ 还是 unschedulableQ ：如果 moveRequestCycle 大于 podSchedulingCycle ，则进入 podBackoffQ ，否则进入 unschedulableQ . 1234567891011121314151617// AddUnschedulableIfNotPresent inserts a pod that cannot be scheduled into// the queue, unless it is already in the queue. Normally, PriorityQueue puts// unschedulable pods in `unschedulableQ`. But if there has been a recent move// request, then the pod is put in `podBackoffQ`.func (p *PriorityQueue) AddUnschedulableIfNotPresent(pInfo *framework.QueuedPodInfo, podSchedulingCycle int64) error &#123; ... // If a move request has been received, move it to the BackoffQ, otherwise move // it to unschedulableQ. if p.moveRequestCycle &gt;= podSchedulingCycle &#123; if err := p.podBackoffQ.Add(pInfo); err != nil &#123; return fmt.Errorf("error adding pod %v to the backoff queue: %v", pod.Name, err) &#125; &#125; else &#123; p.unschedulableQ.addOrUpdate(pInfo) &#125; ...&#125; 何时 moveRequestCycle &gt;= podSchedulingCycle ： 我们在集群资源变更的时候（例如添加 Node 或者删除 Pod），会有回调函数尝试将 unschedulableQ 中之前因为资源不满足需求的 pod 放入 activeQ 或者 podBackoffQ ，及时进行调度。 调度队列会每隔 30s 定时运行 flushUnschedulableQLeftover ，尝试调度 unschedulableQ 中的 pod。 这两者都会调用 movePodsToActiveOrBackoffQueue 函数，并将 moveRequestCycle 设为 p.schedulingCycle. 12345func (p *PriorityQueue) movePodsToActiveOrBackoffQueue(podInfoList []*framework.QueuedPodInfo, event string) &#123; ... p.moveRequestCycle = p.schedulingCycle p.cond.Broadcast()&#125; podBackoffQ 中 pod 的生命周期加入 podBackoffQ 有两种情况会让 pod 加入 podBackoffQ： 调度失败。如果调度失败，并且集群资源发生变更，即 moveRequestCycle &gt;= podSchedulingCycle ，pod 就会加入到 podBackoffQ 中。 从 unschedulableQ 中转移。当集群资源发生变化的时候，最终会调用 movePodsToActiveOrBackoffQueue 将 unschedulableQ 的 pod 转移到 podBackoffQ 或者 activeQ 中。转移到 podBackoffQ 的条件是 p.isPodBackingoff(pInfo) ，即 pod 仍然处于 backoff 状态。 退出 podBackoffQ 调度器会定时让 pod 从 podBackoffQ 转移到 activeQ 中。 在 sched.SchedulingQueue.Run 中运行的 flushBackoffQCompleted cronjob 会每隔 1s 按照优先级（优先级是按照 backoffTime 排序）依次将满足 backoffTime 条件的 pod 从 podBackoffQ 转移到 activeQ 中，直到遇到一个不满足 backoffTime 条件的 pod。 unschedulableQ 中 pod 的生命周期加入 unschedulableQ 只有一种情况会让 pod 加入 unschedulableQ，那就是调度失败。如果调度失败，并且集群资源没有发生变更，即 moveRequestCycle &lt; podSchedulingCycle ，那么 pod 就会加入到 unschedulableQ 中。 退出 unschedulableQ 调度器会同样定时让 pod 从 unschedulableQ 转移到 podBackoffQ 或者 activeQ 中。 在 sched.SchedulingQueue.Run 中运行的 flushUnschedulableQLeftover 最终会调用 movePodsToActiveOrBackoffQueue 将 pod 分别加入到 podBackoffQ 或者 activeQ 中。 总结Kubernetes scheduler 是 kubernetes 中相当重要的组件，基本上各个云平台都会根据自己的业务模型和需求自定义调度器，例如 华为的 Volcano 计算框架。 通过这方面的学习，能在自定义调度器的开发中更加得心应手。 Referencek8s source code 图解kubernetes调度器SchedulingQueue核心源码实现 深入理解k8s调度器与调度框架核心源码 Kubernetes资源调度——scheduler]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MIT6.824 2020 Lab1 MapReduce 实现]]></title>
    <url>%2F2021%2F03%2F12%2FMIT6-824-2020-Lab1-MapReduce-%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[准备工作实验地址：http://nil.csail.mit.edu/6.824/2020/labs/lab-mr.html 论文地址：mapreduce 实验环境可以在实验地址里面找到具体的搭建方式。 系统总览MapReduce 系统是由一个 master 进程和多个 worker 进程组成。 Master 负责任务状态的记录以及任务的分发。 Worker 负责不断向 master 请求任务，并根据任务的类型（map/reduce）进行处理，最后将任务结果发送给 master。 系统框架图如下： 系统流程图如下： 程序基本逻辑Master master 一开始只能分发 map 任务。 当所有 map 任务执行完毕后，master 才开始分发 reduce 任务。 当所有 map 和 reduce 任务执行完毕，master 退出。 对于分发出去的任务，需要进行超时控制，即超时的任务需要重新分发处理。在完成分发任务的同时，对该任务运行一条检测任务超时的 go routine checkTaskTimeout 。 WorkerWorker 调用 GetTask RPC 接口不断向 master 请求任务。当接收到任务，根据任务的类型分类处理。处理完后，调用 CompleteTask 接口告知 master 任务执行完毕。 如果是 map 任务，输入是单个文件，通过 mapf 处理后，使用 ihash(key) % nReduce 决定写入到哪个中间文件，输出是 nReduce 个中间文件。 如果是 reduce 任务，输入是多个 map 输出的中间文件，通过 reducef 处理后，输出是单个文件。 如果没有可执行的任务，则等待一下，继续轮询。 代码结构Master 的结构如下： 12345678910111213141516171819202122// master.gotype Task struct &#123; // Pending, Running and Completed phase string taskID int taskType string // for map, input path has only one element inputPaths []string // for reduce, output path has only one element outputPaths []string&#125;type Master struct &#123; nReduce int mapTasks []*Task reduceTasks []*Task incompletedMapTaskCount int incompletedReduceTaskCount int reduceInitialized bool mux sync.Mutex&#125; Worker 主要是处理逻辑，官方实验文档以及 main/mrsequential.go 里面有例子。 RPC 的结构如下： 123456789101112131415161718// rpc.gotype GetTaskRequest struct&#123;&#125;type GetTaskResponse struct &#123; TaskType string TaskID int TaskInputs []string NReduce int&#125;type CompleteTaskRequest struct &#123; TaskType string TaskID int TaskOutputs []string&#125;type CompleteTaskResponse struct&#123;&#125; 以上是代码的结构，具体的代码细节在 github 上面。 踩过的坑这里最主要的应该是对于并发的控制，以及 crash 的处理。 并发控制加锁可以完成。 crash 的处理是靠 master 的超时机制，以及在 worker 处理的时候，生成一个临时文件，在处理结束后再 rename 成最终的文件。 为了方便 debug，推荐使用 github.com/sirupsen/logrus 这个库。可以将 debug 等级设为 debug level 来输出自己的 debug 信息。 12345678910import ( log "github.com/sirupsen/logrus")log.SetOutput(os.Stdout)// log.SetLevel(log.DebugLevel)log.SetLevel(log.WarnLevel)log.SetFormatter(&amp;log.TextFormatter&#123; FullTimestamp: true,&#125;) 最终结果 这里的 FATAL 是 master 检测到所有任务完成后退出，worker 连接不上 master 而抛出的错误，是预期的。 结语这个实验虽然只是一个小玩具，但还是有收获的。特别是看过论文后进行实验，对 mapreduce 一些细节的实现有更深的了解。有兴趣的同学可以自己完成一遍。]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的协程]]></title>
    <url>%2F2020%2F04%2F05%2FPython%E4%B8%AD%E7%9A%84%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[什么是协程协程是指一个过程，这个过程与调用方协作，产出由调用方提供的值。 协程是程序可以控制的，可以在内部中断。 生成器与协程从句法上看，协程与生成器类似，都是定义体中包含 yield 关键字的函数。但是在协程中， yield 通常会出现在表达式的右边，例如 value = yeild ，可以选择是否产出值，如果 yield 后面没有表达式，那么生成器产出 None。 协程通常包含着协程本身与调用方的数据交互，因此协程可能会从调用方接收数据，不过调用方把数据提供给协程的方式是通过 coroutine.send(value) 方法，而不是 next(coroutinue) 函数。除了 .send(value) 方法之外，还有 .throw(Exception) 和 .close() 方法：前者的作用是让调用方抛出异常，在生成器中处理；后者的作用是终止生成器。 Python 中协程的使用方式本文使用的 Python 环境是 Python3.7.1 。 有了上面的知识，可以写出我们的第一个使用协程的简单例子。 Example 1 123456789101112131415&gt;&gt;&gt; def my_coroutine():... print('start')... value = yield # 这里 value 会接收协程调用方使用 `.send()` 发送的值... print(f'received &#123;value&#125;')... &gt;&gt;&gt; my_coro = my_coroutine()&gt;&gt;&gt; my_coro&lt;generator object my_coroutine at 0x10165bc78&gt;&gt;&gt;&gt; next(my_coro) # 预激协程start&gt;&gt;&gt; my_coro.send("233") # 将值传给协程received 233Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration 协程的状态协程具有四个状态，分别是： GEN_CREATED 等待开始执行。 GEN_RUNNING 解释器正在执行。 GEN_SUSPENDED 在 yield 表达式处暂停。 GEN_CLOSED 执行结束。 要获取协程的状态可以通过 inspect.getgeneratorstate(coroutine) 方法获取。 一开始的时候，协程还处于未激活状态 GEN_CREATED，这时需要使用 next(coroutine) 或者 coroutine.send(None) 方法激活协程。这一步通常叫做 预激(prime) 协程（即让协程向前执行到第一个 yield 表达式，准备好作为活跃的协程使用）。 Tips：如果没有预激协程，那么会抛出一个异常，如下： Example 2 123456789101112131415&gt;&gt;&gt; def my_coroutine():... print('start')... import time... time.sleep(5)... x = yield... print(f'end -&gt; &#123;x&#125;')... &gt;&gt;&gt; coro = my_coroutine()&gt;&gt;&gt; import inspect&gt;&gt;&gt; print(inspect.getgeneratorstate(coro))GEN_CREATED&gt;&gt;&gt; coro.send("233")Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: can't send non-None value to a just-started generator 由于 .send() 方法的参数会成为暂停的 yield 表达式的值，所以仅当协程处于暂停状态时才可以调用 sned 方法，换句话说，调用方在使用 .send() 方法的时候可能会阻塞主程序的运行。例如我们尝试在协程中加上 sleep() 。 Example 3 1234567891011121314151617&gt;&gt;&gt; def my_coroutine():... print('start')... import time... time.sleep(5) # 这里会阻塞主程序 5s... print('sleep 5 ok')... x = yield... print(f'end -&gt; &#123;x&#125;')... &gt;&gt;&gt; &gt;&gt;&gt; coro = my_coroutine()&gt;&gt;&gt; print(coro)&lt;generator object my_coroutine at 0x10a0482a0&gt;&gt;&gt;&gt; print(inspect.getgeneratorstate(coro))GEN_CREATED&gt;&gt;&gt; next(coro)startsleep 5 ok # 5s 后输出 Eample 4 产出多个值 123456789101112131415161718192021222324252627&gt;&gt;&gt; def my_coroutine2(a):... print(f'start: a = &#123;a&#125;')... b = yield a... print(f'b = &#123;b&#125;')... c = yield a + b... print(f'c = &#123;c&#125;')... &gt;&gt;&gt; &gt;&gt;&gt; coro = my_coroutine2(1)&gt;&gt;&gt; print(inspect.getgeneratorstate(coro))GEN_CREATED&gt;&gt;&gt; next(coro)start: a = 11&gt;&gt;&gt; print(inspect.getgeneratorstate(coro))GEN_SUSPENDED&gt;&gt;&gt; coro.send(3) # 把数值 3 发给协程，b 被赋值为 3，计算 `a + b`，得到 4, 产出 `a + b` 的值b = 34&gt;&gt;&gt; coro.send(5)c = 5Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration&gt;&gt;&gt; &gt;&gt;&gt; print(inspect.getgeneratorstate(coro))GEN_CLOSED my_coroutine2() 的执行分为三个阶段： 调用 next(coro)，打印第一个消息，然后执行 yield a，产出 1. 调用 coro.send(3)，把值 3 赋予 b，打印第二个消息，然后执行 yield a + b, 产出 4. 调用 coro.send(5)，把值 5 赋予 c，打印第三个消息，协程终止。 协程的终止与异常处理协程的终止可以调用 coroutine.close() 方法。close() 是会让生成器在暂停的 yield 表达式处抛出 GeneratorExit 异常。如果生成器没有处理这个异常，或者抛出了 StopIteration 异常（通常指运行到结尾），调用方不会报错。 要在协程中抛出异常可以调用 coroutine.throw(...) 方法。throw() 会使生成器在暂停的 yield 表达式处抛出指定异常。如果生成器处理了抛出的异常，代码会向前执行到下一个 yield 表达式，而产出的值会成为调用 throw() 方法得到的返回值。 Example 5 1234567891011121314151617181920212223242526272829303132&gt;&gt;&gt; class CustomException(Exception):... pass... &gt;&gt;&gt; &gt;&gt;&gt; def my_coroutine3():... print('my coroutine3 start...')... while True:... try:... value = yield... except CustomException:... print('Catch custom exception...')... else:... print(f'coroutine3 received value: &#123;value&#125;')... print('coroutine3 terminated by unknown exception...')... &gt;&gt;&gt; &gt;&gt;&gt; coro = my_coroutine3()&gt;&gt;&gt; next(coro)my coroutine3 start...&gt;&gt;&gt; coro.send(5)coroutine3 received value: 5&gt;&gt;&gt; coro.send(20)coroutine3 received value: 20&gt;&gt;&gt; print(inspect.getgeneratorstate(coro))GEN_SUSPENDED&gt;&gt;&gt; coro.throw(CustomException())Catch custom exception...&gt;&gt;&gt; print(inspect.getgeneratorstate(coro))GEN_SUSPENDED&gt;&gt;&gt; coro.close()&gt;&gt;&gt; print(inspect.getgeneratorstate(coro))GEN_CLOSED 获取协程的返回值Example 6 尝试在协程的最后添加 return 语句返回结果。 Example 6 12345678910111213141516171819202122232425&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; &gt;&gt;&gt; Result = namedtuple('Result', 'count average')&gt;&gt;&gt; &gt;&gt;&gt; def averager():... total = 0.0... count = 0... average = None... while True:... value = yield... if value is None:... break... total += value... count += 1... average = total / count... return Result(count, average)... &gt;&gt;&gt; coro = averager()&gt;&gt;&gt; next(coro)&gt;&gt;&gt; coro.send(5)&gt;&gt;&gt; coro.send(20)&gt;&gt;&gt; coro.send(None)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration: Result(count=2, average=12.5) 可以看到协程 return 的值保存在了 StopIteration 的 value 属性中。 于是我们可以修改 Example 6 得到 Example 7, 通过捕获异常去获取返回值： Example 7 1234567891011&gt;&gt;&gt; coro = averager()&gt;&gt;&gt; next(coro)&gt;&gt;&gt; coro.send(5)&gt;&gt;&gt; coro.send(20)&gt;&gt;&gt; try:... coro.send(None)... except StopIteration as e:... result = e.value... &gt;&gt;&gt; print(result)Result(count=2, average=12.5) 这样的程序的缺点很明显，即我们需要添加更多的异常处理。 yield from 可以解决这个问题。 yield fromyield from 会在内部自动捕获 StopIteration 异常，并把异常的 value 属性的值变成 yield from 表达式的值。 举个例子：现在我们有一个动态获取求一组数据的平均结果的需求。 不使用 yield from 的写法如 Example 8 所示。 Example 8 不使用 yield from 12345678910111213141516171819202122232425262728293031323334353637def averager(): total = 0.0 count = 0 average = None while True: value = yield average if value is None: break total += value count += 1 average = total / count return Result(count, average)def main(): data = &#123; "A": [i for i in range(4, 7)], "B": [i for i in range(3)], &#125; results = &#123;&#125; for key, values in data.items(): avg = averager() next(avg) # 预激 group 协程 for value in values: avg.send(value) try: avg.send(None) except StopIteration as e: # catch exception results[key] = e.value print(results)main()===▶ python3 test.py&#123;'A': Result(count=3, average=5.0), 'B': Result(count=3, average=1.0)&#125; 使用 yield from 的代码如 Example 9 所示： Example 9 使用 yield from 123456789101112131415161718192021222324252627282930313233343536373839404142434445from collections import namedtupleResult = namedtuple('Result', 'count average')def averager(): total = 0.0 count = 0 average = None while True: value = yield # value 的值是调用方 main() 中 send 过来的 if value is None: break total += value count += 1 average = total / count return Result(count, average)def grouper(results, key): while True: # Tag results[key] = yield from averager()def main(): data = &#123; "A": [i for i in range(50)], "B": [i for i in range(100)], &#125; results = &#123;&#125; for key, values in data.items(): group = grouper(results, key) next(group) # 预激 group 协程 for value in values: group.send(value) group.send(None) # 终止 averager，处理下一个 key 的 values print(results)main()===▶ python3 test.py&#123;'A': Result(count=3, average=5.0), 'B': Result(count=3, average=1.0)&#125; 使用 yield from 会涉及到下面的术语： 委派生成器：包含 yield from &lt;iterable&gt; 表达式的生成器函数。即 grouper()。 子生成器：从 yield from 表达式中 &lt;iterable&gt; 部分获取的生成器。即 averager()。 调用方：调用委派生成器的客户端代码。即 main()。 yield from 的主要功能是打开双向通道，把最外层的调用方与最内层的子生成器链接起来，这样二者可以直接发送和产出值，还可以直接传入异常，而不用在位于中间的协程添加大量处理异常的样板代码。 Qustion: 为什么在 grouper() 里面需要加 while True 呢？ Answer：由于我们在最后 send(None) 的时候，averager() 直接 break 了，这时候没有再执行到 value = yield 的 yield 处，因此调用方 group.send(None) 拿不到子生成器中 yield 的值，会抛出 StopIteration 异常。我们需要让调用方 group.send(None) 能够拿到 yield 的结果，因此需要再进入子生成器 yield 产出结果给调用方 group.send(None)。 当然 yield from 不只处理了 StopIteration 异常，它还会做一些其他操作，这里是 PEP 380 说明的 yield from 的行为： 子生成器产生的值都返回给委派生成器的调用方。 任何使用 send() 方法发送给委派生成器的值都直接传给子生成器。如果发送的值是 None ，那么会调用子生成器的 __next__() 方法。如果发送的值不是 None，那么会调用子生成器的 send() 方法。如果调用的方法抛出 StopIteration 异常，那么委派生成器恢复执行，其他任何异常都会向上传递给委派生成器。 除了 GeneratorExit 异常以外的其他传入委派生成器的异常，都会传给子生成器的 throw() 方法。如果调用 throw() 方法时抛出 StopIteration 异常，委派生成器恢复运行。 StopIteration 以外的异常都会向上传递给委派生成器。 如果 GeneratorExit 异常被抛给委派生成器，或者委派生成器的 close() 方法被调用，如果子生成器有 close() 的话也将被调用。如果 close() 调用产生异常，异常将传递给委派生成器。否则，委派生成器将抛出 GeneratorExit 异常。 yield from 表达式的值是子生成器终止时传给 StopIteration 异常的第一个参数。 生成器退出时，生成器（或子生成器）中的 return expr 表达式会触发 StopIteration(expr) 异常抛出。 ReferencesFluent Python 本文几乎都是基于这本书的内容做的笔记。 Python Developer’s Guide PEP 380]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的文本和字节]]></title>
    <url>%2F2019%2F09%2F15%2FPython%E4%B8%AD%E7%9A%84%E6%96%87%E6%9C%AC%E5%92%8C%E5%AD%97%E8%8A%82%2F</url>
    <content type="text"><![CDATA[概述最近工作中的项目同时使用到了 Python2 和 Python3 ，遇到了文本和字节的 tricks，自己之前对这方面不太了解，学习并总结一下。 编码介绍Unicode 标准Unicode 是用于表示文本以供计算机进行处理的通用字符编码标准。Unicode 标准提供了一种对多语种纯文本进行一致编码的方法，便于国际文本文件的交换。 字符 的最佳定义是 Unicode 字符 。Unicode 只是一个符号集，它只规定了符号的二进制代码，并没有规定这个二进制代码应该如何存储。 UTF-8UTF-8 字符编码是 Unicode 的实现方式之一。 UTF-8 是一种变长的编码方式，它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 Python 中的文本和字节Python3 中从 str 对象中获取的元素就是 Unicode 字符，可以通过 编码 (encode) 将 文本 转化为 字节。 然而 Python2 中从 str 对象中获取的元素是字节序列，只有通过 解码 (decode) 才能将 字节 转化为 文本 。 下面使用两个版本的 Python 对字符串进行操作以作解释： 123456789# py3&gt;&gt;&gt; s = '123'&gt;&gt;&gt; type(s)&lt;class 'str'&gt; # 文本&gt;&gt;&gt; b = s.encode('utf-8')&gt;&gt;&gt; bb'123'&gt;&gt;&gt; type(b)&lt;class 'bytes'&gt; # 字节序列 12345678910111213141516# py2&gt;&gt;&gt; s = '123'&gt;&gt;&gt; type(s)&lt;type 'str'&gt; # 这里是字节序列&gt;&gt;&gt; b = s.encode('utf-8')&gt;&gt;&gt; b'123'&gt;&gt;&gt; type(b)&lt;type 'str'&gt; # 这里还是字节序列&gt;&gt;&gt; b.decode() # decode 出来的才是文本u'123'&gt;&gt;&gt; type(b.decode())&lt;type 'unicode'&gt; # 文本&gt;&gt;&gt; c = '一二三'&gt;&gt;&gt; c'\xe4\xb8\x80\xe4\xba\x8c\xe4\xb8\x89' # 字节序列 从上面的程序可以总结出 Python2 和 Python3 对于字符串处理上的区别： Python2 Python3 Unicode strings unicode str Bytes strings str bytes Python 中的 u, b, rPython 的字符串有时候前面会加一个 u ，r 或者 b ，其含义如下： u ：表示字符串中的元素是 Unicode 字符。结合上面表格的结论，可以认为：在 Python3 中，字符串前面是否加 u 的效果是一致的。在 Python2 中，字符串前面加 u 表示其中的元素是 Unicode 字符，不加 u 表示 bytes。 b ：表示字符串中的元素是 Bytes。同结合上面表格的结论，可以认为：在 Python2 中，字符串前面是否加 b 的效果是一致的。在 Python3 中，字符串前面加 b 表示其中的元素是 bytes，不加 b 表示 Unicode 字符。 r ：表示字符串是 原始字符串(raw string) ，里面的字符都是 raw string literals ，与 Unicode 和 Bytes 无关，因此 Python2 和 Python3 中含义是一致的。它的作用是使解释器不会对诸如 \n, \t 等转义字符进行转义： 1234567# py3&gt;&gt;&gt; s1 = '123\n123\t123'&gt;&gt;&gt; s1'123\n123\t123'&gt;&gt;&gt; s2 = r'123\n123\t123'&gt;&gt;&gt; s2'123\\n123\\t123' # 不转义 Python2 和 Python3 在字符串处理方面的兼容既然 Python2 和 Python3 在字符串的处理方面有所不同，但是实际工作中却需要写出兼容两种版本的代码，那么应该如何处理呢？ 我的做法是使用 __future__ 模块： 1from __future__ import unicode_literals 该模块的作用是将 Python2 的字符串字面量的类型变为文本，而不是字节，因此与 Python3 是一样的。 举个栗子： 123456789101112# py2&gt;&gt;&gt; from __future__ import unicode_literals&gt;&gt;&gt; s = '123'&gt;&gt;&gt; su'123'&gt;&gt;&gt; type(s)&lt;type 'unicode'&gt; # 文本&gt;&gt;&gt; b = b'123'&gt;&gt;&gt; b'123'&gt;&gt;&gt; type(b)&lt;type 'str'&gt; # 字节 总结目前 Python2 与 Python3 是并存的，因此在编写代码过程中需要注意其中的差异和兼容性，不然就要出锅了hhh（虽然 Python2 在 2020 年 1 月就要停止维护了）。 参考 字符编码笔记 Unicode In Python]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js中异步获取文件集并返回结果集]]></title>
    <url>%2F2019%2F01%2F20%2Fjs%E4%B8%AD%E5%BC%82%E6%AD%A5%E8%8E%B7%E5%8F%96%E6%96%87%E4%BB%B6%E9%9B%86%E5%B9%B6%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C%E9%9B%86%2F</url>
    <content type="text"><![CDATA[概述最近在使用js中经常遇到需要去异步获取文件并对文件内容进行处理的需求。 详细的需求是：同时去异步获取多个文件，然后将多个文件的结果聚合起来，返回。 但是关于这样的做法有不少的实现方式，在这里主要做一个总结。 做法我先在项目中放置了两个需要获取的json文件。 a.json 1234&#123; "a": "1", "b": "2"&#125; b.json 1234&#123; "c": "3", "d": "4"&#125; 接下来开始获取这两个文件。 只使用 Promise/thenPromise/then介绍Promise介绍 关于 Promise，可以看上面的链接，介绍的十分详细。 Promise有一个resolve()方法，将Promise对象的pending状态转化为resolved状态，并将操作的结果作为参数传递出去：例如 new Promise((resolve, reject) =&gt; { resolve(&#39;123&#39;) })，这里会将&#39;123&#39;作为Promise的结果传递出去。 接着可以用then方法去获取结果。then方法只能跟在Promise的后面，因此then方法的两个形参分别是Promise的resolve()方法传入的参数和reject()方法传入的参数。 一个小例子： 123let promise = new Promise((resolve, reject) =&gt; &#123; resolve('123') &#125;)promise.then(data =&gt; console.log(data))// 123 实现异步123456789101112131415161718192021222324252627282930313233let files = ['./data/a.json', './data/b.json'] // 放在相对于index.html目录下的两个json文件let promises = files.map((file) =&gt; &#123; return new Promise((resolve, reject) =&gt; &#123; fetch(file).then((resp) =&gt; &#123; resolve(resp.json()) // resp.json() is a promise，resolve(resp.json())将包含的文件结果的promise传递出去 &#125;) &#125;)&#125;)console.log('A : ', promises) // two promises/*A : (2) [Promise, Promise] 0: Promise [[PromiseStatus]]: "resolved" [[PromiseValue]]: Object a: "1" b: "2" 1: Promise &#123;&lt;resolved&gt;: &#123;…&#125;&#125; length: 2*/// Promise.all()将promises数组转化为一个promise，并获取promises内部的promise的返回值，并将返回值以一个数组的形式传递出去Promise.all(promises).then((results) =&gt; &#123; console.log(results) &#125;)/*(2) [&#123;…&#125;, &#123;…&#125;] 0: a: "1" b: "2" 1: c: "3" d: "4" length: 2*/ 使用async/await使用async函数之前可能还需要了解一下Generator函数。 Generator函数介绍Generator函数不同于普通的函数。它在函数名前面会有一个*的标志，而且内部可以使用yeild使得Generator函数具有一些状态，不会一次执行完毕。 Generator函数可以通过调用next()方法执行到下一个yeild，每次会返回一个包含{value: , done: }的对象，为yeild后面的表达式的结果。可以给next()函数传递值，使得这个值为上一个yeild表达式的返回结果。 123456789101112131415function* genFunc() &#123; let resA = yield '1' console.log(resA) let resB = yield '2' console.log(resB) return '3'&#125;// 此时还未执行gen()let gen = genFunc()// 开始执行第一个yield(yield '1')console.log(gen.next())// 执行第二个yeild(yield '2')，传入的参数为上一个yield的返回值，因此genFunc()中的resA='A'console.log(gen.next('A'))// 执行第三个yeild(return '3')，resB的值与上面同理console.log(gen.next('B')) 结果： async/await介绍async函数介绍 async/await主要是将Generator函数的*替换为async，将yield替换为await，而且await后面需要跟promise，并且等待其执行完成，得到其执行结果；如果不是promise的话，会立即返回其值。另外async函数的返回值是一个promise。 实现异步123456789let files = ['./data/a.json', './data/b.json']async function fetchFilesData(files) &#123; let promises = files.map(async (file) =&gt; &#123; let resp = await fetch(file) // 此时await等待fetch的结果，但是这个过程是并发fetch return resp.json() &#125;) return await Promise.all(promises) // 此时await等待并获取了Promise.all()的执行结果&#125;fetchFilesData(files).then((results) =&gt; &#123; console.log(results) &#125;) // 最后这里还是用.then()去获取，不知道是否存在不用.then()的方法 结果： 使用axios替代fetch听同学说用axios替代fetch会更好，经过查阅资料，主要是有axios从浏览器中创建 XMLHttpRequest，然而fetch是es规范中的实现方式，脱离了XMLHttpRequest，需要更多的配置。具体其他的区别需要在其他使用场景中去注意。 下面是两个方法的返回值的区别： 123let files = ['./data/a.json', './data/b.json']console.log('fetch:', fetch(files[0]))console.log('axios:', axios.get(files[0])) 结果： 可以看到两者的区别。 实现异步123456789let files = ['./data/a.json', './data/b.json']async function fetchFilesData(files) &#123; let promises = files.map((file) =&gt; &#123; return axios.get(file) // 得到一个返回response的promise &#125;) return await Promise.all(promises)&#125;fetchFilesData(files).then((results) =&gt; &#123; return results.map((result) =&gt; &#123;return result.data&#125;) &#125;) .then((data) =&gt; &#123;console.log(data)&#125;) 总结对于不同实现方式的优点和缺点，以及原理尚还不是很清晰，特别是axios和fetch两者，还需要再多多学习。]]></content>
      <categories>
        <category>前端开发</category>
      </categories>
      <tags>
        <tag>前端开发</tag>
        <tag>问题记录</tag>
        <tag>JavaScipt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端css样式覆盖问题]]></title>
    <url>%2F2019%2F01%2F10%2F%E5%89%8D%E7%AB%AFcss%E6%A0%B7%E5%BC%8F%E8%A6%86%E7%9B%96%2F</url>
    <content type="text"><![CDATA[综述今天在使用 D3 的时候遇到一个 css 的问题，这里留作记录防止以后踩坑。 问题在使用 d3 添加鼠标响应事件，想要修改 css，结果不会修改。 123456789101112131415let rec = svg.append("rect") .attr("class", "view") .attr("x", 1) .attr("y", 1) .attr("width", width - 2) .attr("height", height - 2) .attr("fill", "gray") .style("stroke", "red") .style("stroke-width", "2px") .on("mouseover", function() &#123; d3.select(this).classed("hover", true) &#125;) .on("mouseout", function() &#123; d3.select(this).classed("hover", false) &#125;) 12345678910.view:hover &#123; stroke: blue; stroke-width: 2;&#125;.view &#123; stroke: gold; stroke-width: 2; pointer-events: all;&#125; 这里添加了 mouseover 和 mouseout 事件，借此改变 rect 的样式，结果没有成功。 解决方法折腾了好久，问了一下大佬立马解决。 打开 chrome 的调试工具。 可以看到这里 .view:hover 和 .view 都是被 element.style 覆盖了。 这个 element.style 一般是内联样式，因此查看自己的代码，发现在定义 rect 的时候已经定义了 style ： .style(&quot;stroke&quot;, &quot;red&quot;).style(&quot;stroke-width&quot;, &quot;2px&quot;)。 将这两句去掉，可以得到最终结果： hover unhover 完整代码 D3Component.js 12345678910111213141516171819202122232425262728293031323334353637import React from 'react';import * as d3 from 'd3';import './D3Component.css'class D3Component extends React.Component &#123; componentDidMount() &#123; let svg = d3.select("svg"), width = +svg.attr("width"), height = +svg.attr("height"); let rec = svg.append("rect") .attr("class", "view") .attr("x", 1) .attr("y", 1) .attr("width", width - 2) .attr("height", height - 2) .attr("fill", "gray") // .style("stroke", "red") // .style("stroke-width", "2px") .on("mouseover", function() &#123; d3.select(this).classed("hover", true) &#125;) .on("mouseout", function() &#123; d3.select(this).classed("hover", false) &#125;) &#125; render() &#123; return ( &lt;div&gt; &lt;svg id="svg" width="100" height="100"&gt;&lt;/svg&gt; &lt;/div&gt; ) &#125;&#125;export default D3Component; D3Component.css 12345678910.view:hover &#123; stroke: blue; stroke-width: 2;&#125;.view &#123; stroke: gold; stroke-width: 2; pointer-events: all;&#125;]]></content>
      <categories>
        <category>前端开发</category>
      </categories>
      <tags>
        <tag>前端开发</tag>
        <tag>问题记录</tag>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F15%2FHello-World%2F</url>
    <content type="text"><![CDATA[本人是广东某双非本科的计算机系蒟蒻一枚，大一到大三接触过ACM，之后开始接触Java备战春招，暑假在杭州实习。虽然秋招以Java后台开发为目标，但是去了广州某无人驾驶公司，主要使用Python（学了一年的Java最终丢了233）。之前一直是用博客园和简书写一些东西，前两周入职了，开始接触新的东西，建立这个博客也算是新的启程吧。]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
